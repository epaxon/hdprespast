{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "import sys, itertools\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline\n",
    "\n",
    "N = 1000\n",
    "alphabet = string.ascii_lowercase + '#' + '.'\n",
    "D = len(alphabet)\n",
    "z = np.ones(N)\n",
    "\n",
    "RI_pres = np.random.rand(D, N)\n",
    "RI_pres = np.where(RI_pres>0.5, 1, -1)\n",
    "\n",
    "RI_past = np.random.rand(D, N)\n",
    "RI_past = np.where(RI_past>0.5, 1, -1)\n",
    "\n",
    "def read_csv(filepath):\n",
    "    category2word = {}\n",
    "    key = 0\n",
    "    present, past = [], []\n",
    "    num_words = 0\n",
    "    with open(filepath, 'rb') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            if row[0] == \"#\":\n",
    "                category2word[key] = [present, past]\n",
    "                key += 1;\n",
    "                present, past = [], []\n",
    "            else:\n",
    "                present.append(row[0])\n",
    "                past.append(row[1])\n",
    "            num_words += 1\n",
    "    return category2word, num_words\n",
    "\n",
    "def ngram_encode_cl(ngram_str, letter_vecs, window=3):\n",
    "    vec = np.zeros(letter_vecs.shape[1])\n",
    "    full_str = '#' + ngram_str + '.'\n",
    "    for il, l in enumerate(full_str[:-(window-1)]):\n",
    "        trivec = letter_vecs[alphabet.find(full_str[il]), :]\n",
    "        for c3 in range(1, window):\n",
    "            trivec = trivec * np.roll(letter_vecs[alphabet.find(full_str[il+c3]), :], c3)\n",
    "        vec += trivec\n",
    "    return 2* (vec + 0.1*(np.random.rand(letter_vecs.shape[1])-0.5) < 0) - 1\n",
    "\n",
    "# http://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_lda.html#sphx-glr-auto-examples-decomposition-plot-pca-vs-lda-py\n",
    "def lda(category2word, selected_categories, num_diffs, ngram_lengths, colors):\n",
    "    X = np.zeros((num_diffs, N))\n",
    "    y = np.zeros(num_diffs)\n",
    "    for ngram_length in ngram_lengths:\n",
    "        print \"ngram_length %d\" % ngram_length\n",
    "        # Generate observations\n",
    "        for c in selected_categories:\n",
    "            num_subwords = len(category2word[c][0])\n",
    "            for i in range(num_subwords):\n",
    "                X[i] = ngram_encode_cl(category2word[c][1][i], RI_past, ngram_length) - ngram_encode_cl(category2word[c][0][i], RI_pres, ngram_length)\n",
    "                y[i] = c\n",
    "        \n",
    "        clf = LinearDiscriminantAnalysis(n_components=len(selected_categories))\n",
    "        clf.fit(X, y)\n",
    "        y_pred = clf.predict(X)\n",
    "        \n",
    "        print \"expected: \"\n",
    "        print y\n",
    "        print \"actual: \"\n",
    "        print y_pred\n",
    "        print (\"accuracy: \", accuracy_score(y, y_pred))\n",
    "        # argh I can't project by lda\n",
    "        # also the graphs are broken lmao\n",
    "        \"\"\"\n",
    "        pca = PCA(n_components=2)\n",
    "        X_r = pca.fit_transform(X)\n",
    "\n",
    "        print X_r.shape\n",
    "        fig, ax = plt.subplots(figsize=(5,5))\n",
    "        i = 0\n",
    "        for c in selected_categories:\n",
    "            for txt in category2word[c][1]:\n",
    "                ax.annotate(txt, X_r[i])\n",
    "                ax.scatter(X_r[i][0], X_r[i][1], color=available_colors[c])\n",
    "                i += 1\n",
    "        plt.title('LDA expected')\n",
    "        plt.show()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(5,5))\n",
    "        i = 0\n",
    "        for c in selected_categories:\n",
    "            for txt in category2word[c][1]:\n",
    "                ax.annotate(txt, X_r[i])\n",
    "                ax.scatter(X_r[i][0], X_r[i][1], color=available_colors[int(y_pred[i])])\n",
    "                i += 1\n",
    "        plt.title('LDA actual')\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngram_lengths = [2, 3, 4]\n",
    "available_colors = ['green', 'red', 'blue', 'yellow', 'black']\n",
    "irreg_category2word, irreg_num_words = read_csv(\"data/cleaned/irregular_verbs_final_categorize.csv\")\n",
    "reg_category2word, reg_num_words = read_csv(\"data/cleaned/regular_verbs_clean_categorize_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_length 2\n",
      "expected: \n",
      "[ 3.  3.  3.  3.  3.  3.  3.  3.  2.  2.  2.  2.  2.  2.  2.  2.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "actual: \n",
      "[ 0.  0.  3.  3.  3.  2.  3.  3.  2.  2.  0.  0.  0.  2.  2.  2.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "('accuracy: ', 0.84210526315789469)\n",
      "ngram_length 3\n",
      "expected: \n",
      "[ 3.  3.  3.  3.  3.  3.  3.  3.  2.  2.  2.  2.  2.  2.  2.  2.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "actual: \n",
      "[ 0.  0.  3.  3.  0.  3.  0.  3.  0.  2.  0.  0.  0.  2.  2.  2.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "('accuracy: ', 0.78947368421052633)\n",
      "ngram_length 4\n",
      "expected: \n",
      "[ 3.  3.  3.  3.  3.  3.  3.  3.  2.  2.  2.  2.  2.  2.  2.  2.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "actual: \n",
      "[ 0.  0.  0.  0.  3.  3.  3.  3.  0.  0.  0.  0.  0.  0.  0.  2.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "('accuracy: ', 0.71052631578947367)\n"
     ]
    }
   ],
   "source": [
    "# looking only at categories:\n",
    "irreg_selected_categories = [0, 1, 2, 3]\n",
    "irreg_num_diffs = 0\n",
    "for c in irreg_selected_categories:\n",
    "    irreg_num_diffs += len(irreg_category2word[c][0])\n",
    "lda(irreg_category2word, irreg_selected_categories, irreg_num_diffs, ngram_lengths, available_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_length 2\n",
      "expected: \n",
      "[ 2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "actual: \n",
      "[ 1.  0.  1.  0.  2.  1.  1.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  0.\n",
      "  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "('accuracy: ', 0.79591836734693877)\n",
      "ngram_length 3\n",
      "expected: \n",
      "[ 2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "actual: \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "('accuracy: ', 0.38775510204081631)\n",
      "ngram_length 4\n",
      "expected: \n",
      "[ 2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "actual: \n",
      "[ 1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0.  1.  1.  1.  0.  1.  0.  0.\n",
      "  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "('accuracy: ', 0.40816326530612246)\n"
     ]
    }
   ],
   "source": [
    "# looking only at categories:\n",
    "reg_selected_categories = [0, 1, 2]\n",
    "reg_num_diffs = 0\n",
    "for c in reg_selected_categories:\n",
    "    reg_num_diffs += len(reg_category2word[c][0])\n",
    "lda(reg_category2word, reg_selected_categories, reg_num_diffs, ngram_lengths, available_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
