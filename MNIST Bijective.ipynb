{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hrr_utils\n",
    "import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home='mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = mnist.data\n",
    "labels = mnist.target\n",
    "\n",
    "(data, labels) = utils.Shuffle(data, labels)\n",
    "N=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def project_mnist(inp, projection_mat):\n",
    "    inp = np.where(inp > 0, 1, 0).astype(np.float32)\n",
    "    # Look only at presence 1\n",
    "    vec = np.sign(inp.dot(projection_mat))\n",
    "    return vec\n",
    "\n",
    "def random_vec(num_elements, n=N):\n",
    "    # Everything has equal chance (.5) of being pos, neg\n",
    "    # returns num_elements x N\n",
    "    return np.where(np.random.random((num_elements, N)) > .5, 1, -1)\n",
    "\n",
    "hamming = lambda x, y: np.sign(x.reshape((1, -1))).dot(np.sign(y.reshape((-1, 1))))\n",
    "# Hamming similarity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio = .8\n",
    "\n",
    "train_set = data[:int(len(data)*ratio)]\n",
    "train_label = labels[:int(len(data)*ratio)]\n",
    "test_set = data[int(len(data)*ratio):]\n",
    "test_label = labels[int(len(data)*ratio) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n"
     ]
    }
   ],
   "source": [
    "(train_set, train_label) = utils.Shuffle(train_set, train_label)\n",
    "\n",
    "N = 1000\n",
    "W = np.zeros((N, N), dtype=np.float32)\n",
    "random_labels = random_vec(10, N)\n",
    "projection_mat = np.random.random((784, N))-.5\n",
    "\n",
    "\n",
    "\n",
    "for i in range(train_label.shape[0]):\n",
    "    if i%1000 == 0:\n",
    "        print i\n",
    "    dat = project_mnist(train_set[i], projection_mat).reshape((1, N))\n",
    "    label = random_labels[int(train_label[i])].reshape((1, N))\n",
    "    \n",
    "    pred = (label-dat.dot(W)/N)\n",
    "    W += dat.T.dot(pred)\n",
    "\n",
    "k1 = []\n",
    "k2 = []\n",
    "for j in range(test_label.shape[0]):\n",
    "    dat = project_mnist(test_set[j], projection_mat).reshape((1, N))\n",
    "    label = random_labels[int(test_label[j])].reshape((1, N))\n",
    "    k1.append((dat.dot(W)/N).dot(label.T))\n",
    "    k2.append(hamming(dat.dot(W), label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722.198378133\n",
      "705.555571429\n"
     ]
    }
   ],
   "source": [
    "print np.array(k1).mean()\n",
    "print np.array(k2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:11: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "corr = 0 \n",
    "\n",
    "error = np.zeros((10, 10))\n",
    "\n",
    "for j in range(1000):\n",
    "    dat = project_mnist(test_set[j], projection_mat).reshape((1, N))\n",
    "    label = random_labels[int(test_label[j])].reshape((1, N))\n",
    "\n",
    "    vec = (dat.dot(W)/N).dot(random_labels.T)\n",
    "    corr += np.argmax(vec) == test_label[j]\n",
    "    error[np.argmax(vec), test_label[j]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83755357142857145"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr+0.0)/len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "error = np.zeros((10, 10))\n",
    "corr = 0\n",
    "\n",
    "for j in range(len(train_set)):\n",
    "    dat = project_mnist(train_set[j], projection_mat).reshape((1, N))\n",
    "    label = random_labels[int(train_label[j])].reshape((1, N))\n",
    "\n",
    "    vec = (dat.dot(W)/N).dot(random_labels.T)\n",
    "    corr += np.argmax(vec) == train_label[j]\n",
    "    error[np.argmax(vec), train_label[j]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1,  1, -1,  1,  1, -1, -1,  1, -1,  1, -1, -1,  1,  1,  1, -1,\n",
       "        -1, -1,  1, -1,  1,  1, -1,  1, -1, -1,  1, -1, -1, -1,  1,  1,  1,\n",
       "         1,  1,  1, -1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1, -1, -1, -1,\n",
       "         1,  1,  1,  1,  1, -1, -1, -1,  1,  1, -1, -1,  1,  1,  1, -1, -1,\n",
       "         1,  1, -1,  1, -1,  1, -1, -1,  1, -1,  1,  1, -1,  1, -1,  1, -1,\n",
       "         1,  1,  1,  1,  1,  1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1,\n",
       "        -1,  1, -1, -1,  1, -1, -1,  1, -1,  1,  1,  1,  1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1,  1,  1, -1, -1,  1,\n",
       "         1, -1,  1, -1,  1, -1,  1, -1,  1, -1, -1,  1, -1, -1,  1, -1, -1,\n",
       "        -1, -1,  1,  1, -1, -1,  1, -1,  1, -1,  1,  1, -1, -1, -1,  1,  1,\n",
       "        -1, -1,  1,  1, -1, -1,  1, -1,  1, -1, -1, -1,  1,  1,  1,  1, -1,\n",
       "        -1,  1, -1, -1, -1,  1, -1, -1, -1,  1,  1,  1, -1,  1,  1,  1,  1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1,\n",
       "        -1,  1,  1, -1,  1,  1,  1,  1, -1, -1, -1, -1,  1, -1, -1, -1, -1,\n",
       "         1,  1,  1,  1,  1,  1, -1, -1,  1,  1, -1, -1,  1, -1,  1,  1,  1,\n",
       "        -1, -1, -1,  1, -1, -1,  1,  1,  1, -1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        -1, -1, -1,  1,  1, -1, -1,  1, -1,  1,  1,  1,  1, -1, -1,  1,  1,\n",
       "         1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1,  1, -1,  1,\n",
       "        -1, -1, -1, -1,  1, -1, -1, -1,  1,  1, -1,  1,  1,  1, -1,  1, -1,\n",
       "         1,  1,  1,  1,  1, -1, -1,  1,  1, -1, -1,  1,  1,  1, -1,  1,  1,\n",
       "         1,  1, -1,  1, -1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1, -1, -1,\n",
       "         1, -1, -1,  1, -1, -1,  1, -1,  1,  1, -1, -1, -1,  1, -1, -1, -1,\n",
       "        -1,  1,  1, -1,  1,  1, -1, -1, -1, -1, -1,  1, -1, -1,  1,  1,  1,\n",
       "        -1, -1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1, -1, -1,\n",
       "        -1,  1, -1,  1, -1, -1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,  1,\n",
       "        -1,  1, -1,  1, -1,  1, -1,  1,  1,  1, -1,  1,  1, -1, -1,  1,  1,\n",
       "        -1, -1, -1,  1, -1, -1,  1, -1,  1,  1,  1, -1,  1, -1, -1,  1, -1,\n",
       "         1, -1, -1, -1,  1,  1, -1,  1, -1,  1, -1, -1, -1,  1,  1,  1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,  1,  1,  1,  1, -1,  1,\n",
       "         1,  1, -1, -1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        -1, -1, -1, -1,  1,  1, -1, -1,  1, -1,  1, -1, -1,  1, -1, -1,  1,\n",
       "         1,  1, -1,  1,  1,  1, -1,  1, -1,  1,  1, -1, -1, -1,  1,  1, -1,\n",
       "        -1, -1, -1,  1,  1, -1, -1,  1, -1, -1, -1,  1,  1, -1, -1,  1, -1,\n",
       "         1,  1, -1, -1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "        -1,  1,  1, -1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1, -1, -1,  1,\n",
       "        -1,  1,  1,  1, -1,  1, -1,  1, -1,  1,  1, -1,  1,  1, -1,  1, -1,\n",
       "         1, -1,  1,  1,  1,  1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         1, -1,  1,  1,  1, -1, -1,  1,  1,  1, -1,  1,  1, -1,  1,  1, -1,\n",
       "         1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1, -1, -1, -1, -1, -1,\n",
       "         1, -1, -1, -1,  1, -1, -1, -1,  1,  1, -1,  1,  1,  1,  1, -1,  1,\n",
       "         1, -1,  1,  1,  1, -1,  1, -1, -1,  1,  1, -1,  1,  1,  1,  1, -1,\n",
       "        -1,  1,  1, -1,  1,  1,  1,  1, -1, -1, -1, -1, -1,  1, -1,  1, -1,\n",
       "         1, -1, -1, -1, -1,  1, -1,  1,  1, -1, -1, -1, -1,  1,  1, -1,  1,\n",
       "        -1,  1, -1, -1,  1,  1, -1,  1, -1,  1, -1, -1, -1, -1,  1,  1, -1,\n",
       "         1,  1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1, -1,  1, -1,  1, -1,\n",
       "         1, -1, -1, -1,  1, -1,  1,  1,  1, -1, -1, -1,  1,  1, -1, -1,  1,\n",
       "         1,  1,  1,  1,  1, -1,  1, -1,  1,  1, -1, -1, -1,  1, -1,  1, -1,\n",
       "         1,  1,  1,  1,  1, -1,  1,  1, -1, -1, -1,  1, -1, -1, -1,  1, -1,\n",
       "        -1, -1,  1, -1, -1, -1, -1,  1, -1, -1,  1, -1, -1,  1, -1, -1,  1,\n",
       "        -1, -1, -1,  1,  1,  1, -1, -1, -1,  1,  1,  1, -1,  1,  1, -1, -1,\n",
       "        -1,  1,  1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1,  1, -1,\n",
       "         1, -1, -1, -1,  1,  1, -1,  1,  1, -1, -1,  1, -1,  1,  1,  1, -1,\n",
       "         1, -1, -1, -1, -1,  1, -1,  1,  1,  1, -1,  1, -1, -1,  1,  1, -1,\n",
       "         1,  1, -1,  1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1,  1, -1,\n",
       "        -1,  1,  1,  1, -1, -1, -1,  1,  1,  1, -1,  1, -1,  1,  1,  1,  1,\n",
       "         1,  1, -1, -1, -1, -1, -1, -1,  1, -1,  1,  1, -1,  1,  1, -1, -1,\n",
       "         1, -1,  1,  1, -1,  1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1,\n",
       "         1,  1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1, -1,  1,  1,\n",
       "        -1,  1,  1,  1,  1,  1,  1, -1,  1, -1, -1,  1,  1, -1]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave = np.mean(train_set, axis=0)\n",
    "\n",
    "def project_mnist2(inp, projection_mat):\n",
    "    n = inp-ave;\n",
    "    filt2 = (n<0).astype(np.float)\n",
    "    filt3 = (n>0).astype(np.float)\n",
    "    \n",
    "    total_filt = filt3-filt2\n",
    "    \n",
    "    return np.where(total_filt.dot(np.sign(projection_mat)).reshape([1, N])>=0, 1, -1)\n",
    "\n",
    "project_mnist2(test_set[0], projection_mat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "1000 86.0817\n",
      "2000 90.4369\n",
      "3000 104.916\n",
      "4000 118.652\n",
      "5000 122.507\n",
      "6000 119.54\n",
      "7000 122.783\n",
      "8000 128.634\n",
      "9000 114.259\n",
      "10000 121.736\n",
      "11000 126.908\n",
      "12000 143.96\n",
      "13000 147.363\n",
      "14000 130.598\n",
      "15000 128.099\n",
      "16000 139.321\n",
      "17000 128.377\n",
      "18000 125.172\n",
      "19000 122.686\n",
      "20000 139.842\n",
      "21000 149.125\n",
      "22000 151.954\n",
      "23000 134.538\n",
      "24000 148.038\n",
      "25000 158.966\n",
      "26000 164.271\n",
      "27000 171.283\n",
      "28000 181.035\n",
      "29000 182.162\n",
      "30000 171.856\n",
      "31000 181.242\n",
      "32000 190.699\n",
      "33000 192.39\n",
      "34000 189.505\n",
      "35000 185.982\n",
      "36000 197.219\n",
      "37000 180.742\n",
      "38000 177.633\n",
      "39000 174.26\n",
      "40000 187.258\n",
      "41000 175.11\n",
      "42000 184.488\n",
      "43000 191.038\n",
      "44000 187.454\n",
      "45000 185.747\n",
      "46000 178.363\n",
      "47000 189.159\n",
      "48000 174.379\n",
      "49000 170.272\n",
      "50000 165.566\n",
      "51000 164.561\n",
      "52000 179.977\n",
      "53000 168.8\n",
      "54000 172.954\n",
      "55000 167.377\n"
     ]
    }
   ],
   "source": [
    "(train_set, train_label) = utils.Shuffle(train_set, train_label)\n",
    "\n",
    "N = 1000\n",
    "W = np.zeros((N, N), dtype=np.float32)\n",
    "random_labels = random_vec(10, N)\n",
    "projection_mat = np.random.random((784, N))-.5\n",
    "\n",
    "\n",
    "\n",
    "for i in range(train_label.shape[0]):\n",
    "    if i%1000 == 0:\n",
    "        print i, np.max(W)\n",
    "    dat = project_mnist2(train_set[i], projection_mat).reshape((1, N))\n",
    "    label = random_labels[int(train_label[i])].reshape((1, N))\n",
    "    \n",
    "    pred = (label-dat.dot(W)/N)\n",
    "    W += dat.T.dot(pred)\n",
    "    \n",
    "k1 = []\n",
    "k2 = []\n",
    "for j in range(test_label.shape[0]):\n",
    "    dat = project_mnist2(test_set[j], projection_mat).reshape((1, N))\n",
    "    label = random_labels[int(test_label[j])].reshape((1, N))\n",
    "    k1.append((dat.dot(W)/N).dot(label.T))\n",
    "    k2.append(hamming(dat.dot(W), label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       ..., \n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan]], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
