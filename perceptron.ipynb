{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to work with phonemes: http://www.nltk.org/_modules/nltk/corpus/reader/cmudict.html\n",
    "# from nltk.corpus import brown\n",
    "# from nltk.corpus import cmudict\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height has been deprecated.\n",
      "\n",
      "2016-10-29 23:48\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from numpy import array, dot, random\n",
    "from random import choice\n",
    "from utils import random_idx\n",
    "from string import digits\n",
    "\n",
    "# http://www.nltk.org/_modules/nltk/corpus/reader/cmudict.html\n",
    "def read_examples(filepath):\n",
    "    examples = []\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            for word in line.split():\n",
    "                examples.append(word)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign every phoneme to a feature vector\n",
    "k = 500\n",
    "N = 1000\n",
    "ordered = 1\n",
    "NUM_CLASSES = 2 # 0 for non-ed verb, 1 for ed verb\n",
    "\n",
    "# add # to check 2 letters at a time\n",
    "phonemes = [\"AA\", \"AE\", \"AH\", \"AO\", \"AW\", \"AY\", \"B#\", \"CH\", \"D#\", \"DH\", \"EH\", \"ER\", \"EY\", \"F#\", \"G#\", \"HH\", \"IH\",\n",
    "            \"IY\", \"JH\", \"K#\", \"L#\", \"M#\", \"N#\", \"NG\", \"OW\", \"OY\", \"P#\", \"R#\", \"S#\", \"SH\", \"T#\", \"TH\", \"UH\", \"UW\",\n",
    "            \"V#\", \"W#\", \"Y#\", \"Z#\", \"ZH\"\n",
    "           ]\n",
    "RI_phonemes = random_idx.generate_phoneme_id_vectors(N, k, phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first association is between ed verbs and their present tense\n",
    "nonedpast = read_examples(\"wickle_train/noned_past_example.txt\")\n",
    "edpast = read_examples(\"wickle_train/ed1000.txt\")\n",
    "past = nonedpast + edpast\n",
    "ytrain = np.ones(len(past))\n",
    "ytrain[:len(nonedpast)]  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode verbs as phonemes, then \n",
    "# Preprocessing:\n",
    "# DONE: phonetic encoding of verbs based on cmu dictionary\n",
    "    \n",
    "arpabet = nltk.corpus.cmudict.dict()\n",
    "can_phoneme = []\n",
    "for i in range(len(past)):\n",
    "    if past[i] in arpabet.keys():\n",
    "        can_phoneme.append(past[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581, 1000)\n",
      "[[ 1. -1.  1. ...,  1. -1. -1.]\n",
      " [-1. -1.  1. ..., -1. -1.  1.]\n",
      " [ 1. -1.  1. ...,  1.  1. -1.]\n",
      " ..., \n",
      " [ 1.  1.  1. ...,  1.  1.  1.]\n",
      " [-1. -1. -1. ...,  1.  1. -1.]\n",
      " [ 1.  1.  1. ..., -1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "Xtrain = np.zeros((len(can_phoneme), N))\n",
    "ytrain = np.ones(len(can_phoneme))\n",
    "for i in range(len(can_phoneme)):\n",
    "    phonemed = [s.encode(\"ascii\").translate(None, digits) for s in arpabet[can_phoneme[i]][0]]\n",
    "    phonemed = [s if len(s) > 1 else s +\"#\" for s in phonemed]\n",
    "    #print(can_phoneme[i], phonemed)\n",
    "    Xtrain[i] = random_idx.phoneme_id_vector(N, \"\".join(phonemed), phonemed, phonemes, RI_phonemes)\n",
    "print(Xtrain.shape)\n",
    "print Xtrain\n",
    "# make the test set the brown corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n",
      "1.0: 0.0 -> 1\n"
     ]
    }
   ],
   "source": [
    "# https://blog.dbrgn.ch/2013/3/26/perceptrons-in-python/\n",
    "# or \n",
    "# http://sebastianraschka.com/Articles/2015_singlelayer_neurons.html\n",
    "# does not guarantee large/good margin.\n",
    "unit_step = lambda x: 0 if x < 0 else 1\n",
    "\n",
    "Xtrain = np.zeros((len(can_phoneme), N))\n",
    "ytrain = np.ones(len(can_phoneme))\n",
    "\n",
    "w = random.rand(N)\n",
    "errors = []\n",
    "eta = 0.2\n",
    "n = 100\n",
    "\n",
    "selected_indices = np.random.choice(Xtrain.shape[0], n)\n",
    "for i in selected_indices:\n",
    "    x, y = Xtrain[i], ytrain[i]\n",
    "    result = dot(w, x)\n",
    "    error = y - unit_step(result)\n",
    "    errors.append(error)\n",
    "    w += eta * error * x\n",
    "\n",
    "results = np.dot(Xtrain, w)\n",
    "for i in range(len(results)):\n",
    "    print(\"{}: {} -> {}\".format(ytrain[i], result, unit_step(result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocessing:\n",
    "\n",
    "Pentti:\n",
    "These are my notes on learning the past tense of\n",
    "English verbs (\"Chapter18.pdf\" of Rumelhart &\n",
    "McClelland 1986) from the meeting on Friday.  We'll\n",
    "learn their model and the Perceptron Learning Rule\n",
    "by reproducing the work in sections \"Learning\" and\n",
    "\"Learning Regular and Exceptional Patterns in a Pattern\n",
    "Associator\" (pp. 225-233).  It's a simple exercise with\n",
    "artificial data.  Here's what I'd like you to do:\n",
    "\n",
    "1. First see how Figure 3 corresponds to having learned\n",
    "   one of the association (one input-output pair).\n",
    "\n",
    "2. Then start with an 8 x 8 matrix of 0s and train it\n",
    "   for that same association using the perceptron-\n",
    "   learning rule, to get a matrix that looks like Table\n",
    "   1A.  Because training is stochastic, the numbers you\n",
    "   get will not be exactly the same.\n",
    "\n",
    "3. Do the same with the other association (Table 2B).\n",
    "\n",
    "4. Then reproduce Table 2C.  Now we are learning two\n",
    "   associations.\n",
    "\n",
    "5. Figure out what they mean by \"Rule of 78\" and see if\n",
    "   you can reproduce the equivalent of Table 2D.\n",
    "\n",
    "6. Finally, see if you can reproduce all four stages\n",
    "   shown in Table 4.\n",
    "\n",
    "I'd like to see all 8 matrices you get, all that\n",
    "correspond to those sown in Tables 2 and 4.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
